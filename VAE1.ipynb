{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:34:02.590034Z",
     "start_time": "2024-08-05T11:33:56.271055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, ReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K"
   ],
   "id": "ad9aa9ed6e3c2414",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T12:10:05.179016Z",
     "start_time": "2024-08-05T12:10:05.167434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "#定义了一个名为VAE_BN的类，继承自object类\n",
    "class VAE_BN:\n",
    "\n",
    "    #这是类的构造函数，接受三个参数：nSpecFeatures（光谱特征的数量），intermediate_dim（中间层的维度），和latent_dim（潜在空间的维度）。\n",
    "    def __init__(self, nSpecFeatures, intermediate_dim, latent_dim):\n",
    "        self.nSpecFeatures = nSpecFeatures\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.latent_dim = latent_dim\n",
    "    #定义了一个名为sampling的方法，该方法实现了重参数化技巧，这是VAE中的一个关键步骤，用于从编码器的输出中采样。\n",
    "    #在sampling方法中，args是一个包含两个元素的元组，分别是z_mean（潜在空间的均值）和z_log_var（潜在空间的对数方差）。\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        #这里使用Keras后端函数tf.random_normal生成一个形状为(batch_size, latent_dim)的正态分布随机矩阵epsilon。\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))  # random_normal (mean=0 and std=1)\n",
    "        #通过重参数化技巧，从正态分布中采样，并返回潜在空间的样本。\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ],
   "id": "e5205d6bdee916f2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T12:34:48.470580Z",
     "start_time": "2024-08-05T12:34:48.459143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class VAE_BN:\n",
    "    # ... 其他类定义 ...\n",
    "\n",
    "    def get_architecture(self):\n",
    "        # =========== 1. Encoder Model================\n",
    "        #定义了输入数据的形状，其中self.nSpecFeatures是类的一个属性，表示输入特征的数量。\n",
    "        input_shape = (self.nSpecFeatures, )\n",
    "        #创建了一个Keras的Input层，它是编码器的输入层，具有指定的形状和名称。\n",
    "        inputs = tf.keras.Input(shape=input_shape, name='encoder_input')\n",
    "        #添加了一个全连接层（Dense），其神经元数量由self.intermediate_dim指定，并将输入数据传递给它。\n",
    "        h = tf.keras.layers.Dense(self.intermediate_dim)(inputs)\n",
    "        #在上一层的输出上应用批量归一化（BatchNormalization），这有助于提高训练的稳定性和速度。\n",
    "        h = tf.keras.layers.BatchNormalization()(h)\n",
    "        #应用ReLU激活函数，它对输入数据的每个元素应用非线性操作，保留正数元素，并将负数元素置为零。\n",
    "        h = tf.keras.layers.ReLU()(h)\n",
    "        #添加了另一个全连接层，其神经元数量由self.latent_dim指定，用于输出潜在空间的均值，并命名为z_mean。\n",
    "        z_mean = tf.keras.layers.Dense(self.latent_dim, name='z_mean')(h)\n",
    "        #对z_mean层的输出应用批量归一化。\n",
    "        z_mean = tf.keras.layers.BatchNormalization()(z_mean)\n",
    "        #添加了另一个全连接层，同样输出潜在空间的维度，但这次用于输出潜在空间的对数方差，并命名为z_log_var。\n",
    "        z_log_var = tf.keras.layers.Dense(self.latent_dim, name='z_log_var')(h)\n",
    "        #对z_log_var层的输出应用批量归一化。\n",
    "        z_log_var = tf.keras.layers.BatchNormalization()(z_log_var)\n",
    "        # ... 可能需要返回或进一步处理这些层 ...\n"
   ],
   "id": "8fe0720fd2ae1378",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T13:32:29.538404Z",
     "start_time": "2024-08-05T13:32:29.499022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class VAE_BN:\n",
    "    # ... 其他类定义 ...\n",
    "\n",
    "    def get_architecture(self):\n",
    "        # ... 之前的编码器定义 ...\n",
    "\n",
    "        # 解码器定义\n",
    "        latent_inputs = tf.keras.Input(shape=(self.latent_dim,), name='Latent_Space')\n",
    "        hdec = tf.keras.layers.Dense(self.intermediate_dim)(latent_inputs)\n",
    "        hdec = tf.keras.layers.BatchNormalization()(hdec)\n",
    "        hdec = tf.keras.layers.ReLU()(hdec)\n",
    "        outputs = tf.keras.layers.Dense(self.nSpecFeatures, activation='sigmoid')(hdec)\n",
    "        decoder = tf.keras.Model(latent_inputs, outputs, name='decoder')\n",
    "        print(\"==== Decoder Architecture...\")\n",
    "        decoder.summary()\n",
    "\n",
    "        # ... 可能需要返回或进一步处理这些层 ...\n",
    "\n"
   ],
   "id": "700976da219cc0e7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class VAE_BN:\n",
    "    # ... 其他类定义 ...\n",
    "\n",
    "    def get_architecture(self):\n",
    "        # ... 之前的编码器和解码器定义 ...\n",
    "\n",
    "        # 构建VAE模型\n",
    "        outputs = self.decoder(self.encoder(inputs)[2])\n",
    "        self.VAE_BN_model = tf.keras.Model(inputs, outputs, name='VAE_BN')\n",
    "\n",
    "        # ====== Cost Function (Variational Lower Bound)  ==============\n",
    "        \"KL-div (regularizes encoder) and reconstruction loss (of the decoder): see equation(3) in our paper\"\n",
    "        # 1. KL-Divergence:\n",
    "        kl_Loss = 1 + self.z_log_var - tf.square(self.z_mean) - tf.exp(self.z_log_var)\n",
    "        kl_Loss = tf.reduce_sum(kl_Loss, axis=-1)\n",
    "        kl_Loss *= -0.5\n",
    "        # 2. Reconstruction Loss\n",
    "        reconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, outputs)  # Use sigmoid at output layer\n",
    "        reconstruction_loss *= self.nSpecFeatures\n",
    "\n",
    "        # ========== Compile VAE_BN model ===========\n",
    "        model_Loss = tf.reduce_mean(reconstruction_loss + kl_Loss)\n",
    "        self.VAE_BN_model.add_loss(model_Loss)\n",
    "        self.VAE_BN_model.compile(optimizer='adam')\n",
    "        return self.VAE_BN_model, self.encoder\n",
    "\n",
    "# 示例用法\n",
    "vae_bn = VAE_BN(nSpecFeatures=..., intermediate_dim=..., latent_dim=...)\n",
    "vae_bn_model, encoder = vae_bn.get_architecture()\n"
   ],
   "id": "bef4903a0ccf7c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a1b5ea0e910e6ac9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
